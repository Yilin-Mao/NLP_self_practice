{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code and (maybe) some thoughts on \\< nlp in action \\> ch3 and ch4 (partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3.4 主题建模'''\n",
    "#文档词频率\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from Collections import Counter\n",
    "from nlpia.data.loaders import kite_text, kite_history #注：python3.10可能会出现问题\n",
    "tokenizer = TreebankWordTokenizer\n",
    "kite_intro = kite_text.lower()\n",
    "intro_tokens = tokenizer.tokenize(kite_intro)\n",
    "kite_history = kite_history.lower()\n",
    "history_tokens = tokenizer.tokenize(kite_history)\n",
    "intro_total = len(intro_tokens)\n",
    "\n",
    "#词频率\n",
    "intro_tf = {}\n",
    "intro_counts = Counter(intro_tokens)\n",
    "intro_tf['kite'] = intro_counts['kite']/intro_total\n",
    "\n",
    "#稀缺度\n",
    "num_docs_containing_kite = 0\n",
    "for doc in [intro_tokens, history_tokens]:\n",
    "    if 'kite' in doc:\n",
    "        num_docs_containing_kite += 1\n",
    "\n",
    "intro_idf = {}\n",
    "intro_idf['kite'] = num_doc / num_docs_containing_kite\n",
    "\n",
    "#考虑文档内部词频率与包含该词文档数\n",
    "intro_tfidf = {}\n",
    "intro_tfidf['kite'] = intro_tf['kite'] * intro_idf['kite']\n",
    "\n",
    "'''TF-IDF DEFINE\n",
    "log_tf = log(term_occurences_in_doc) - log(num_terms_in_doc)\n",
    "log_log_idf = log(log(total_num_docs)-log(num_docs_containing_term))\n",
    "log_tf_idf = log_tf+log_idf'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3.4.2 相关度排序'''\n",
    "document_tfidf_vector = []\n",
    "for doc in docs:\n",
    "    vec = copy.copy(zerovector)\n",
    "    tokens = tokenizer.tokenizer(doc.lower())\n",
    "    token_counts = Counter(tokens)\n",
    "\n",
    "    for key, value in token_counts.items():\n",
    "        docs_containing_key = 0\n",
    "        for _doc in docs:\n",
    "            if key in _doc:\n",
    "                docs_containing_key += 1\n",
    "        tf = value / len(lexicon)\n",
    "        if docs_containing_key:\n",
    "            idf = len(docs)/docs_containing_key\n",
    "        else:\n",
    "            idf = 0\n",
    "        vec[key] = tf*idf\n",
    "\n",
    "    document_tfidf_vector.append(vec)\n",
    "\n",
    "\n",
    "    query = 'How long does it take to get to the store'\n",
    "    query_vec = copy.copy(zero_vector)\n",
    "    '''similar process to get query_vec'''\n",
    "    cosine_sim(query_vec, document_tfidf_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   0.58 0.   0.58 0.   0.58]\n",
      " [0.45 0.45 0.45 0.   0.45 0.   0.45 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "'''3.4.3 sklearn构建TF-IDF矩阵'''\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "docs = ['a men wearing a shirt','crazy beach on the floor']\n",
    "corpus = docs\n",
    "vectorize = TfidfVectorizer(min_df=1)\n",
    "model = vectorize.fit_transform(corpus)\n",
    "print(model.todense().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''4.2隐性语义分析,4.3奇异值分解'''\n",
    "#based on SVD, implement LSA\n",
    "from nlpia.book.examples.ch04_catdog_lsa_3x6x16 import word_topic_vectors\n",
    "from nlpia.book.examples.ch04_catdog_lsa_sorted import lsa_models, prettify_tdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(word_topic_vectors.T.round(1))\n",
    "\n",
    "bow_svd, tfidf_svd = lsa_models() #svd分解\n",
    "tdm = bow_svd['tdm']\n",
    "\n",
    "U, s, Vt = np.linalg.svd(tdm)\n",
    "pd.DataFrame(U, index=tdm.index).round(2) #U矩阵是主题-词矩阵，将词-文档向量转化为主题-文档向量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''4.4主成分分析'''\n",
    "#基于PCA的短消息语义分析\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=16)\n",
    "pca = pca.fit(tfidf_docs)\n",
    "pca_topic_vectors = pca.transform(tfidf_docs) #文档-主题矩阵\n",
    "\n",
    "column_nums, terms = zip(*sorted(zip(tfidf.vocabulary_.values(),tfidf.vocabulary_keys())))\n",
    "weights = pd.DataFrame(pca.components_, columns=terms, index=['topic{}'.format(i) for i in range(16)])\n",
    "deals = weights['! ; ] : ] half off free crazy deal only '.split()]\n",
    "deals.T.sum() #得到不同主题关于交易的情感倾向（正/负）\n",
    "\n",
    "#基于截断的SVD语义分析\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=16, n_iter=100)\n",
    "svd_topic_vectors = svd.fit_transform(tfidf_docs.values)\n",
    "svd_topic_vectors = pd.DataFrame(svd_topic_vectors, columns=columns, index=index)\n",
    "\n",
    "#基于LSA的垃圾分类\n",
    "import numpy as np\n",
    "svd_topic_vectors = (svd_topic_vectors.T/ np.linalg.norm(svd_topic_vectors, axis=1)).T\n",
    "svd_topic_vectors.iloc[:10].dot(svd_topic_vectors.iloc[:10].T).round(1) #归一化并计算向量之间的距离\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
